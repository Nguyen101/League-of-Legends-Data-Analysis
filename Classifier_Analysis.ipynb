{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# League of Legends Analysis\n",
    "# Vy Nguyen and Daniel Strub\n",
    "# CPSC 322"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import sys\n",
    "import os\n",
    "import copy\n",
    "from tabulate import tabulate\n",
    "\n",
    "import mysklearn.myutils\n",
    "importlib.reload(mysklearn.myutils)\n",
    "import mysklearn.myutils as myutils\n",
    "\n",
    "import mysklearn.mypytable\n",
    "importlib.reload(mysklearn.mypytable)\n",
    "from mysklearn.mypytable import MyPyTable \n",
    "\n",
    "import mysklearn.myclassifiers\n",
    "importlib.reload(mysklearn.myclassifiers)\n",
    "from mysklearn.myclassifiers import MyKNeighborsClassifier, MySimpleLinearRegressor, MyNaiveBayesClassifier, MyDecisionTreeClassifier\n",
    "\n",
    "import mysklearn.myevaluation\n",
    "importlib.reload(mysklearn.myevaluation)\n",
    "import mysklearn.myevaluation as myevaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_fname = os.path.join(\"input_data\", \"games_small.csv\")\n",
    "game_table = MyPyTable()\n",
    "game_table.load_from_file(game_fname)\n",
    "\n",
    "game_ID = game_table.get_column(\"gameId\")\n",
    "winner = game_table.get_column(\"winner\")\n",
    "first_Blood = game_table.get_column(\"firstBlood\")\n",
    "first_Tower = game_table.get_column(\"firstTower\")\n",
    "first_Inhibitor = game_table.get_column(\"firstInhibitor\")\n",
    "first_Baron = game_table.get_column(\"firstBaron\")\n",
    "first_Dragon = game_table.get_column(\"firstDragon\")\n",
    "first_RiftHerald = game_table.get_column(\"firstRiftHerald\")\n",
    "\n",
    "game_X = [[first_Blood[x], first_Tower[x], first_Inhibitor[x], first_Baron[x], first_Dragon[x], first_RiftHerald[x]] for x in range(len(game_ID))]\n",
    "game_Y = [y for y in game_ID]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "58.55723714914327% of gmaes with first blood are won\n68.9245949729982% of gmaes with first tower are won\n79.83198879925328% of gmaes with first inhibitor are won\n49.09660644042936% of gmaes with first Baron are won\n65.60437362490833% of gmaes with first dragon are won\n34.00226681778785% of gmaes with first Rift Herald are won\n"
     ]
    }
   ],
   "source": [
    "print(str(myutils.get_win_count(game_table, \"winner\", \"firstBlood\") * 100) + \"% of games with first blood are won\")\n",
    "\n",
    "print(str(myutils.get_win_count(game_table, \"winner\", \"firstTower\") * 100) + \"% of games with first tower are won\")\n",
    "\n",
    "print(str(myutils.get_win_count(game_table, \"winner\", \"firstInhibitor\") * 100) + \"% of games with first inhibitor are won\")\n",
    "\n",
    "print(str(myutils.get_win_count(game_table, \"winner\", \"firstBaron\") * 100) + \"% of games with first Baron are won\")\n",
    "\n",
    "print(str(myutils.get_win_count(game_table, \"winner\", \"firstDragon\") * 100) + \"% of games with first dragon are won\")\n",
    "\n",
    "print(str(myutils.get_win_count(game_table, \"winner\", \"firstRiftHerald\") * 100) + \"% of games with first Rift Herald are won\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "KNN:\nAccuracy = 0.0\nError rate = 1.0\n"
     ]
    }
   ],
   "source": [
    "# KNNeightbors\n",
    "test_size = 10\n",
    "X_train, X_test, y_train, y_test = myevaluation.train_test_split(copy.deepcopy(game_X), copy.deepcopy(game_Y), test_size=test_size, shuffle=True)\n",
    "\n",
    "nb = MyKNeighborsClassifier()\n",
    "nb.fit(X_train, y_train)\n",
    "predictions = []\n",
    "for i, x in enumerate(X_test):\n",
    "    prediction = nb.predict([x])\n",
    "    predictions.append(prediction[0])\n",
    "\n",
    "acc = round(sum([int(x==y) for x,y in zip(predictions, y_test)])/len(predictions), 2)\n",
    "print(\"KNN:\" )\n",
    "print(\"Accuracy = \" + str(acc))\n",
    "print(\"Error rate = \" + str(1-acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Naive Bayes: \nAccuracy = 0.0\nError rate = 1.0\n"
     ]
    }
   ],
   "source": [
    "nb_predicted = []\n",
    "nb_actual = []\n",
    "# Stratified kfold cross validation\n",
    "X_train_folds, X_test_folds = myevaluation.stratified_kfold_cross_validation(game_X, game_Y, n_splits=10)\n",
    "for i in range(0, 1):\n",
    "    X_train, X_test, y_train, y_test = myutils.get_trains_and_tests(game_X, game_Y, X_train_folds[i], X_test_folds[i])\n",
    "    nb = MyKNeighborsClassifier()\n",
    "    nb.fit(X_train, y_train)\n",
    "    predictions = []\n",
    "    for i, x in enumerate(X_test):\n",
    "        prediction = nb.predict([x])\n",
    "        predictions.append(prediction[0])\n",
    "    predicted = [ x for x in predictions]\n",
    "    actual = [x for x in y_test]\n",
    "    \n",
    "    nb_predicted +=  predicted\n",
    "    nb_actual += actual\n",
    "# Result\n",
    "acc = round(sum([int(x==y) for x,y in zip(predicted, actual)])/len(predicted), 2)\n",
    "print(\"Naive Bayes: \")\n",
    "print(\"Accuracy = \" + str(acc))\n",
    "print(\"Error rate = \" + str(1-acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "IndexError",
     "evalue": "list index out of range",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-38c18c3ed563>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# Sort training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mxtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmyutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute_data_by_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_folds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mytrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmyutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute_data_by_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_folds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mxtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmyutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute_data_by_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_folds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/Shared/League-of-Legends-Data-Analysis/mysklearn/myutils.py\u001b[0m in \u001b[0;36mdistribute_data_by_index\u001b[0;34m(data, indices)\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[0mdata_subset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m         \u001b[0mdata_subset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata_subset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# Decision Tree for now\n",
    "test_size = 10\n",
    "predicted_tree = []\n",
    "actual_tree = []\n",
    "\n",
    "# Get training data with stratified kfold cross validation\n",
    "train_folds, test_folds = myevaluation.stratified_kfold_cross_validation(game_X, game_Y, test_size)\n",
    "for i in range(test_size):\n",
    "    # Sort training data\n",
    "    xtrain = myutils.distribute_data_by_index(X_train, train_folds[i])\n",
    "    ytrain = myutils.distribute_data_by_index(Y_train, train_folds[i])\n",
    "    xtest = myutils.distribute_data_by_index(X_train, test_folds[i])\n",
    "    ytest = myutils.distribute_data_by_index(Y_train, test_folds[i])\n",
    "\n",
    "    # Compute prediction and convert\n",
    "    tree = MyDecisionTreeClassifier()\n",
    "    tree.fit(xtrain, ytrain)\n",
    "    predicted = tree.predict(xtest)\n",
    "    predicted_tree += predicted\n",
    "    actual_tree += ytest\n",
    "    \n",
    "# Result\n",
    "acc = round(sum([int(x==y) for x,y in zip(predicted_tree, actual_tree)])/len(predicted_tree), 2)\n",
    "error_rate = 1- accuracy\n",
    "\n",
    "print(\"Decision Tree: \")\n",
    "print(\"Accuracy = \" + str(acc) )\n",
    "print(\"Error Rate = \" + str(1-acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python385jvsc74a57bd098b0a9b7b4eaaa670588a142fd0a9b87eaafe866f1db4228be72b4211d12040f",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}